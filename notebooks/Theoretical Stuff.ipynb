{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our GARCH model\n",
    "\n",
    "* Assumption: exo variable is normally distributed with $ X_t \\sim N(0, 1) $\n",
    "\n",
    "Mean Model\n",
    "$$ r_t = e_t $$ \n",
    "$$e_t \\sim N(0, \\sigma_t^2)$$\n",
    "\n",
    "Volatility Model \n",
    "$$ \\sigma_t^2 = \\omega +  \\alpha e_{t-1}^2 + \\beta \\sigma_{t-i}^2 + \n",
    "    \\gamma x_t^2$$\n",
    "\n",
    "$$x_t \\sim N(0, 1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log likelihood\n",
    " $$ l(\\omega, \\alpha, \\beta, \\gamma) =  \\sum_{t=1}^T {\\frac{1}{2} ({-\\log{2\\pi} -\\log{\\sigma_t^2} - \\frac{e_t^2}{\\sigma_t^2}})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asymtotic distribution of parameters.\n",
    "\n",
    "1. Find first partial derivative for each parameter. For example for $\\gamma$,\n",
    "\n",
    "$$ \\begin{split}\n",
    "    \\frac{\\partial l}{\\partial \\gamma} &= \\frac{\\partial l}{\\partial \\sigma^2} \\frac{\\partial \\sigma^2}{\\partial \\gamma} \\\\\n",
    "    &= \\sum_{t=1}^T \\frac{x_t^2}{2\\sigma_t^2} (\\frac{e_{t}^2}{\\sigma_t^2} -1)\n",
    "\\end{split} $$\n",
    "\n",
    "\n",
    "\n",
    "2.  Find second partial derivative for each parameter, to each parameter. For four parameters, we will have 16 partial derivatives. For instance,\n",
    "\n",
    "$$ \\begin{split}\n",
    "    \\frac{\\partial^2 l}{\\partial \\gamma^2} &= \\frac{\\partial}{\\partial \\sigma^2} (\\frac{\\partial l }{\\partial \\gamma}) \\frac{\\partial \\sigma^2}{\\partial \\gamma} \\\\\n",
    "    &= \\sum_{t=1}^T \\frac{x_t^4}{\\sigma_t^4} (\\frac{1}{2} - \\frac{e_t^2}{\\sigma_t^2})\n",
    "\\end{split} $$\n",
    "\n",
    "3. Find the expectation of the negative of each second partial derivative. Question: do we need to find the expectation, or is the raw form of the second derivative (such as shown in step 2) sufficient?\n",
    "\n",
    "4. This 4x4 matrix then forms our fisher information matrix, $I_E(\\theta)$ where $\\theta$ is the vector of our parameters.\n",
    "\n",
    "5. The asymptotic distribution of our parameters follows a multi variate normal distribution with mean $(\\omega_0, \\alpha_0, \\beta_0, \\gamma_0), $ and variance as the inverse fisher information matrix mentioned in step 3. \n",
    "\n",
    "6. Using the variance, we can find the p value associated with each parameter.\n",
    "\n",
    "---\n",
    "Questions:\n",
    "1. Do we need the regularity conditions for the log likelihood function to hold in order for asymptotic normality and consistency to hold? If so, is this where our assumptions of parameter boundaries and distributions come into place?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
