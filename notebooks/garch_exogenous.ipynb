{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import scipy.optimize as opt\n",
    "\n",
    "import yfinance as yf\n",
    "#from vol_model.volatility_model import VolatilityModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GARCH:\n",
    "    '''\n",
    "    This class defines the GARCH model object which contains, functions\n",
    "    for estimation and VaR forecasting.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, params=None, mu=None):\n",
    "        # Initialize parameters\n",
    "        if (params != None):\n",
    "            self.params = np.array(params)\n",
    "        else:\n",
    "            self.params = np.array([1.e-06, 0.09, 0.9])\n",
    "        if (mu == None):\n",
    "            self.mu = 0\n",
    "        else:\n",
    "            self.mu = mu\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"omega = {:.3g}\\nalpha = {:.3g}\\nbeta  = {:.3g}\".format(*self.params)\n",
    "\n",
    "    def train(self, init_params, y, x=None, callback_func=None):\n",
    "        self.n_obs = len(y)\n",
    "        #self.start_date = str(y.index[0])\n",
    "        #self.end_date = str(y.index[-1])\n",
    "        opt_result = opt.minimize(self.log_likelihood,\n",
    "                           x0=self.inv_repam(init_params),\n",
    "                           args=(y, x, True),  # arguments for function to be minimized (y, fmin=True)\n",
    "                           method='BFGS',\n",
    "                           callback=callback_func,\n",
    "                           options={'maxiter': 100})\n",
    "        self.params = self.repam(opt_result.x)\n",
    "        print('\\nResults of BFGS minimization\\n{}\\n{}'.format(''.join(['-']*28), opt_result))\n",
    "        print('\\nResulting params = {}'.format(self.params))\n",
    "\n",
    "\n",
    "    def log_likelihood(self, params_repam, y, x=None, fmin=False):\n",
    "        '''\n",
    "        Takes the reparametrized 3X1 numpy array gamma = log((omega,alpha,beta))\n",
    "        as input (if given or else uses the ones in self namespace).\n",
    "        And returns either sum of all likelihood contributions that is a 1X1\n",
    "        numpy array or both the likelihood and the (t_max,) numpy array of estimated conditional variances.\n",
    "        '''\n",
    "        self.params = self.repam(params_repam)\n",
    "        omega = self.params[0]\n",
    "        alpha = self.params[1]\n",
    "        beta = self.params[2]\n",
    "        if x is not None:\n",
    "            gammas = self.params[3:]\n",
    "\n",
    "        t_max = len(y)\n",
    "        avg_log_like = 0\n",
    "        sigma2 = np.zeros(t_max + 1)\n",
    "        sigma2[0] = np.var(y)\n",
    "        for t in range(1, t_max):\n",
    "            if x is not None:\n",
    "                sigma2[t] = omega + alpha * y[t - 1] ** 2 + beta * sigma2[t - 1] + (gammas * x[t]).sum() \n",
    "            else:\n",
    "                sigma2[t] = omega + alpha * y[t - 1] ** 2 + beta * sigma2[t - 1]\n",
    "            avg_log_like += (np.log (sigma2[t]) + (y[t] - self.mu)**2 / sigma2[t]) / t_max\n",
    "        if fmin:\n",
    "            return avg_log_like\n",
    "        else:\n",
    "            return [avg_log_like, sigma2]\n",
    "\n",
    "    def filter(self, y):\n",
    "        omega = self.params[0]\n",
    "        alpha = self.params[1]\n",
    "        beta = self.params[2]\n",
    "\n",
    "        t_max = len(y)\n",
    "        sigma2 = np.zeros(t_max + 1)\n",
    "        sigma2[0] = np.var(y)\n",
    "        for t in range(1, t_max):\n",
    "            sigma2[t] = omega + alpha * y[t - 1] ** 2 + beta * sigma2[t - 1]\n",
    "        return sigma2\n",
    "\n",
    "    def repam(self, params_repam):\n",
    "        return np.exp(params_repam)\n",
    "\n",
    "    def inv_repam(self, params):\n",
    "        return np.log(params)\n",
    "\n",
    "    def VaR(self, y, pct=(0.01, 0.025, 0.05)):\n",
    "        est_variance = self.log_likelihood(y=y, fmin=False)[1]\n",
    "        VaR = {}\n",
    "        for alpha in pct:\n",
    "            VaR[str(alpha)] = self.mu + norm.ppf(alpha) * np.sqrt(est_variance)\n",
    "        return VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>Log_Returns</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04 00:00:00-05:00</th>\n",
       "      <td>1116.560059</td>\n",
       "      <td>1133.869995</td>\n",
       "      <td>1116.560059</td>\n",
       "      <td>1132.989990</td>\n",
       "      <td>3991400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05 00:00:00-05:00</th>\n",
       "      <td>1132.660034</td>\n",
       "      <td>1136.630005</td>\n",
       "      <td>1129.660034</td>\n",
       "      <td>1136.520020</td>\n",
       "      <td>2491020000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06 00:00:00-05:00</th>\n",
       "      <td>1135.709961</td>\n",
       "      <td>1139.189941</td>\n",
       "      <td>1133.949951</td>\n",
       "      <td>1137.140015</td>\n",
       "      <td>4972660000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07 00:00:00-05:00</th>\n",
       "      <td>1136.270020</td>\n",
       "      <td>1142.459961</td>\n",
       "      <td>1131.319946</td>\n",
       "      <td>1141.689941</td>\n",
       "      <td>5270680000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08 00:00:00-05:00</th>\n",
       "      <td>1140.520020</td>\n",
       "      <td>1145.390015</td>\n",
       "      <td>1136.219971</td>\n",
       "      <td>1144.979980</td>\n",
       "      <td>4389590000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Open         High          Low        Close  \\\n",
       "Date                                                                            \n",
       "2010-01-04 00:00:00-05:00  1116.560059  1133.869995  1116.560059  1132.989990   \n",
       "2010-01-05 00:00:00-05:00  1132.660034  1136.630005  1129.660034  1136.520020   \n",
       "2010-01-06 00:00:00-05:00  1135.709961  1139.189941  1133.949951  1137.140015   \n",
       "2010-01-07 00:00:00-05:00  1136.270020  1142.459961  1131.319946  1141.689941   \n",
       "2010-01-08 00:00:00-05:00  1140.520020  1145.390015  1136.219971  1144.979980   \n",
       "\n",
       "                               Volume  Dividends  Stock Splits  Log_Returns  \n",
       "Date                                                                         \n",
       "2010-01-04 00:00:00-05:00  3991400000        0.0           0.0          NaN  \n",
       "2010-01-05 00:00:00-05:00  2491020000        0.0           0.0     0.003111  \n",
       "2010-01-06 00:00:00-05:00  4972660000        0.0           0.0     0.000545  \n",
       "2010-01-07 00:00:00-05:00  5270680000        0.0           0.0     0.003993  \n",
       "2010-01-08 00:00:00-05:00  4389590000        0.0           0.0     0.002878  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Download S&P 500 data for the last year\n",
    "start = datetime(2010, 1, 1)\n",
    "end = datetime(2024, 9, 10)\n",
    "snp = yf.Ticker('^GSPC')\n",
    "data = snp.history(start=start, end=end)\n",
    "\n",
    "# Step 2: Compute log returns\n",
    "data['Log_Returns'] = np.log(data['Close'] / data['Close'].shift(1)).dropna()\n",
    "log_returns = data['Log_Returns'].dropna()\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "sentiment_df = pd.read_csv('../data/nyt_sentiment.csv')\n",
    "sentiment_df.index = pd.DatetimeIndex(sentiment_df['adjusted_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.index = pd.DatetimeIndex(data.index.tz_localize(None))\n",
    "data_with_sentiment = data.join(sentiment_df, how='inner')\n",
    "\n",
    "log_returns = data_with_sentiment['Log_Returns']\n",
    "exo_sentiment = data_with_sentiment[['mean_pos_sentiment',\t'mean_neg_sentiment', 'mean_neutral_sentiment']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wei Hao\\AppData\\Local\\Temp\\ipykernel_13464\\2527338683.py:58: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  sigma2[t] = omega + alpha * y[t - 1] ** 2 + beta * sigma2[t - 1]\n",
      "C:\\Users\\Wei Hao\\AppData\\Local\\Temp\\ipykernel_13464\\2527338683.py:59: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  avg_log_like += (np.log (sigma2[t]) + y[t]**2 / sigma2[t]) / t_max\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results of BFGS minimization\n",
      "----------------------------\n",
      "  message: Optimization terminated successfully.\n",
      "  success: True\n",
      "   status: 0\n",
      "      fun: 0.7441101867261453\n",
      "        x: [-3.359e+00 -1.857e+00 -2.062e-01]\n",
      "      nit: 17\n",
      "      jac: [ 2.764e-06 -5.364e-07  1.013e-06]\n",
      " hess_inv: [[ 3.231e+01  1.040e+01 -3.396e+00]\n",
      "            [ 1.040e+01  1.591e+01 -2.801e+00]\n",
      "            [-3.396e+00 -2.801e+00  6.324e-01]]\n",
      "     nfev: 96\n",
      "     njev: 24\n",
      "\n",
      "Resulting params = [0.0347648  0.15615129 0.81364313]\n"
     ]
    }
   ],
   "source": [
    "garch_baseline = GARCH()\n",
    "garch_baseline.train([0.5]*3, 100*log_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garch_with_sentiment = GARCH()\n",
    "garch_with_sentiment.train([0.5]*6, 100*log_returns, exo_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "\n",
    "model = arch_model(100*log_returns, vol='GARCH', mean='Zero', p=1, q=1)\n",
    "garch_fit = model.fit(disp='off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Zero Mean - GARCH Model Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Log_Returns</td>    <th>  R-squared:         </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Mean Model:</th>         <td>Zero Mean</td>     <th>  Adj. R-squared:    </th>  <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Vol Model:</th>            <td>GARCH</td>       <th>  Log-Likelihood:    </th> <td>  -4768.75</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Distribution:</th>        <td>Normal</td>       <th>  AIC:               </th> <td>   9543.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>        <td>Maximum Likelihood</td> <th>  BIC:               </th> <td>   9562.15</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                        <td></td>          <th>  No. Observations:  </th>    <td>3694</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Sat, Nov 02 2024</td>  <th>  Df Residuals:      </th>    <td>3694</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>13:31:21</td>      <th>  Df Model:          </th>      <td>0</td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Volatility Model</caption>\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>       <th>P>|t|</th>     <th>95.0% Conf. Int.</th>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>omega</th>    <td>    0.0348</td> <td>7.386e-03</td> <td>    4.714</td> <td>2.427e-06</td> <td>[2.034e-02,4.930e-02]</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alpha[1]</th> <td>    0.1563</td> <td>1.910e-02</td> <td>    8.184</td> <td>2.745e-16</td>   <td>[  0.119,  0.194]</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beta[1]</th>  <td>    0.8135</td> <td>1.971e-02</td> <td>   41.265</td>   <td>0.000</td>     <td>[  0.775,  0.852]</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Covariance estimator: robust"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:} &    Log\\_Returns    & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Mean Model:}    &     Zero Mean      & \\textbf{  Adj. R-squared:    } &     0.000   \\\\\n",
       "\\textbf{Vol Model:}     &       GARCH        & \\textbf{  Log-Likelihood:    } &   -4768.75  \\\\\n",
       "\\textbf{Distribution:}  &       Normal       & \\textbf{  AIC:               } &    9543.51  \\\\\n",
       "\\textbf{Method:}        & Maximum Likelihood & \\textbf{  BIC:               } &    9562.15  \\\\\n",
       "\\textbf{}               &                    & \\textbf{  No. Observations:  } &    3694     \\\\\n",
       "\\textbf{Date:}          &  Sat, Nov 02 2024  & \\textbf{  Df Residuals:      } &    3694     \\\\\n",
       "\\textbf{Time:}          &      13:31:21      & \\textbf{  Df Model:          } &     0       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lccccc}\n",
       "                  & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{95.0\\% Conf. Int.}  \\\\\n",
       "\\midrule\n",
       "\\textbf{omega}    &       0.0348  &    7.386e-03     &     4.714  &      2.427e-06       &   [2.034e-02,4.930e-02]     \\\\\n",
       "\\textbf{alpha[1]} &       0.1563  &    1.910e-02     &     8.184  &      2.745e-16       &     [  0.119,  0.194]       \\\\\n",
       "\\textbf{beta[1]}  &       0.8135  &    1.971e-02     &    41.265  &        0.000         &     [  0.775,  0.852]       \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Zero Mean - GARCH Model Results}\n",
       "\\end{center}\n",
       "\n",
       "Covariance estimator: robust"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                       Zero Mean - GARCH Model Results                        \n",
       "==============================================================================\n",
       "Dep. Variable:            Log_Returns   R-squared:                       0.000\n",
       "Mean Model:                 Zero Mean   Adj. R-squared:                  0.000\n",
       "Vol Model:                      GARCH   Log-Likelihood:               -4768.75\n",
       "Distribution:                  Normal   AIC:                           9543.51\n",
       "Method:            Maximum Likelihood   BIC:                           9562.15\n",
       "                                        No. Observations:                 3694\n",
       "Date:                Sat, Nov 02 2024   Df Residuals:                     3694\n",
       "Time:                        13:31:21   Df Model:                            0\n",
       "                              Volatility Model                              \n",
       "============================================================================\n",
       "                 coef    std err          t      P>|t|      95.0% Conf. Int.\n",
       "----------------------------------------------------------------------------\n",
       "omega          0.0348  7.386e-03      4.714  2.427e-06 [2.034e-02,4.930e-02]\n",
       "alpha[1]       0.1563  1.910e-02      8.184  2.745e-16     [  0.119,  0.194]\n",
       "beta[1]        0.8135  1.971e-02     41.265      0.000     [  0.775,  0.852]\n",
       "============================================================================\n",
       "\n",
       "Covariance estimator: robust\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "garch_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
